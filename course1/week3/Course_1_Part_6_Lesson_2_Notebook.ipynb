{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6gHiH-I7uFa"
   },
   "source": [
    "#Improving Computer Vision Accuracy using Convolutions\n",
    "\n",
    "In the previous lessons you saw how to do fashion recognition using a Deep Neural Network (DNN) containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and a hidden layer. You experimented with the impact of different sizes of hidden layer, number of training epochs etc on the final accuracy.\n",
    "\n",
    "For convenience, here's the entire code again. Run it and take a note of the test accuracy that is printed out at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcsRtq9OLorS",
    "outputId": "72eb3af3-cdf8-4b19-aec5-ec4641616b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6365 - accuracy: 0.7803\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3874 - accuracy: 0.8620\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3391 - accuracy: 0.8779\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3061 - accuracy: 0.8886\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2931 - accuracy: 0.8936\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images / 255.0\n",
    "test_images=test_images / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zldEXSsF8Noz"
   },
   "source": [
    "Your accuracy is probably about 89% on training and 87% on validation...not bad...But how do you make that even better? One way is to use something called Convolutions. I'm not going to details on Convolutions here, but the ultimate concept is that they narrow down the content of the image to focus on specific, distinct, details. \n",
    "\n",
    "If you've ever done image processing using a filter (like this: https://en.wikipedia.org/wiki/Kernel_(image_processing)) then convolutions will look very familiar.\n",
    "\n",
    "In short, you take an array (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection. So, for example, if you look at the above link, you'll see a 3x3 that is defined for edge detection where the middle cell is 8, and all of its neighbors are -1. In this case, for each pixel, you would multiply its value by 8, then subtract the value of each neighbor. Do this for every pixel, and you'll end up with a new image that has the edges enhanced.\n",
    "\n",
    "This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n",
    "\n",
    "That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.\n",
    "\n",
    "Run the below code -- this is the same neural network as earlier, but this time with Convolutional layers added first. It will take longer, but look at the impact on the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0tFgT1MMKi6",
    "outputId": "729e0184-2b42-46fc-d646-fb154f9ff171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.5898 - accuracy: 0.7875\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2980 - accuracy: 0.8908\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2497 - accuracy: 0.9069\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2170 - accuracy: 0.9179\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1843 - accuracy: 0.9304\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9088\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRLfZ0jt-fQI"
   },
   "source": [
    "It's likely gone up to about 93% on the training data and 91% on the validation data. \n",
    "\n",
    "That's significant, and a step in the right direction!\n",
    "\n",
    "Try running it for more epochs -- say about 20, and explore the results! But while the results might seem really good, the validation results may actually go down, due to something called 'overfitting' which will be discussed later. \n",
    "\n",
    "(In a nutshell, 'overfitting' occurs when the network learns the data from the training set really well, but it's too specialised to only that data, and as a result is less effective at seeing *other* data. For example, if all your life you only saw red shoes, then when you see a red shoe you would be very good at identifying it, but blue suade shoes might confuse you...and you know you should never mess with my blue suede shoes.)\n",
    "\n",
    "Then, look at the code again, and see, step by step how the Convolutions were built:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaLX5cgI_JDb"
   },
   "source": [
    "Step 1 is to gather the data. You'll notice that there's a bit of a change here in that the training data needed to be reshaped. That's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images. If you don't do this, you'll get an error when training as the Convolutions do not recognize the shape. \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SS_W_INc_kJQ"
   },
   "source": [
    "Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
    "\n",
    "1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
    "2. The size of the Convolution, in this case a 3x3 grid\n",
    "3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
    "4. In the first layer, the shape of the input data.\n",
    "\n",
    "You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
    "\n",
    "You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
    "\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMorM6daADjA"
   },
   "source": [
    "Add another convolution\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1-x-kZF4_tC"
   },
   "source": [
    "Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Flatten(),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPtqR23uASjX"
   },
   "source": [
    "The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0GSsjUhAaSj"
   },
   "source": [
    "Now compile the model, call the fit method to do the training, and evaluate the loss and accuracy from the test set.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXx_LX3SAlFs"
   },
   "source": [
    "# Visualizing the Convolutions and Pooling\n",
    "\n",
    "This code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-6nX4QsOku6",
    "outputId": "46d705d5-8ea3-4ee5-bdab-948ae487aae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
      " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
      " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "9FGsHhv6JvDx",
    "outputId": "ab1e8824-6ae3-4a00-9b3b-91f7f31edcbe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KVPZqgHo5Ux"
   },
   "source": [
    "EXERCISES\n",
    "\n",
    "1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.\n",
    "\n",
    "2. Remove the final Convolution. What impact will this have on accuracy or training time?\n",
    "\n",
    "3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.\n",
    "\n",
    "4. Remove all Convolutions but the first. What impact do you think this will have? Experiment with it. \n",
    "\n",
    "5. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpYRidBXpBPM",
    "outputId": "9898462e-19f3-427e-c678-94658c139005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3014 - accuracy: 0.9088\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0520 - accuracy: 0.9847\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0311 - accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0122 - accuracy: 0.9963\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9840\n",
      "0.984000027179718\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JF7V3VTd86G1",
    "outputId": "72835e87-6496-4625-ec02-e257022b7297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5930 - accuracy: 0.7885\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3009 - accuracy: 0.8910\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2505 - accuracy: 0.9077\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2114 - accuracy: 0.9225\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1897 - accuracy: 0.9277\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9079\n",
      "0.9078999757766724\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imu4R4xF-E1K"
   },
   "source": [
    "#### Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goSGB5Bv9wnF",
    "outputId": "9e389cba-60e6-4f67-9148-b957d9ceaf96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 55,098\n",
      "Trainable params: 55,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6970 - accuracy: 0.7563\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3489 - accuracy: 0.8721\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3070 - accuracy: 0.8882\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2810 - accuracy: 0.8955\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2586 - accuracy: 0.9026\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8911\n",
      "0.8910999894142151\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyqNR9ok_w78"
   },
   "source": [
    "#### Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nQyPDkT_42r",
    "outputId": "f8d8c814-a4cd-4589-ad50-860f12489e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               991360    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,030,218\n",
      "Trainable params: 1,030,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5245 - accuracy: 0.8102\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2628 - accuracy: 0.9019\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2003 - accuracy: 0.9261\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1634 - accuracy: 0.9388\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1249 - accuracy: 0.9531\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.9177\n",
      "0.9176999926567078\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC5nK0d9_Afl"
   },
   "source": [
    "#### Exercise 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fj8GOGLq-bKZ",
    "outputId": "7fe82738-4e12-48fc-fe84-6bce0d37217c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 84,106\n",
      "Trainable params: 84,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7883 - accuracy: 0.7154\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4116 - accuracy: 0.8518\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3417 - accuracy: 0.8744\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2965 - accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2743 - accuracy: 0.8992\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8834\n",
      "0.883400022983551\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D-voxhyANVe"
   },
   "source": [
    "#### Exercise 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DHwWJAr_NGW",
    "outputId": "0b2b4d62-2eab-4820-facd-57f254cda604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               5537920   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 5,539,850\n",
      "Trainable params: 5,539,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4952 - accuracy: 0.8239\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2469 - accuracy: 0.9100\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1829 - accuracy: 0.9326\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1359 - accuracy: 0.9497\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1087 - accuracy: 0.9607\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.9045\n",
      "0.9045000076293945\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHK_GURxC5ep"
   },
   "source": [
    "#### Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBsvpc78ATRE",
    "outputId": "c257242f-7e0c-4f5b-db6a-966f43df804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6017 - accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3007 - accuracy: 0.8914\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2444 - accuracy: 0.9099\n",
      "\n",
      "Reached 90% accuracy so cancelling training!\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.8972\n",
      "0.8971999883651733\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if (logs.get('accuracy')>0.9):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[myCallback()])\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Course 1 - Part 6 - Lesson 2 - Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
